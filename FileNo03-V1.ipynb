{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\shant\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (14,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#importing necessary packages\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling as pp\n",
    "#from collections import Counter\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#loading csv into dataframe\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/shantanudeshpande94/bankruptcy-prediction/master/3year.csv'\n",
    "bankruptcy_df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to replace '?' with NA values\n",
    "\n",
    "bankruptcy_df.replace({'?': None},inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attr1       0\n",
       "Attr2       0\n",
       "Attr3       0\n",
       "Attr4      18\n",
       "Attr5      25\n",
       "         ... \n",
       "Attr61     17\n",
       "Attr62     43\n",
       "Attr63     18\n",
       "Attr64    228\n",
       "class       0\n",
       "Length: 65, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to check null values in a column\n",
    "\n",
    "bankruptcy_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attr1        0.052844\n",
       "Attr2        0.619911\n",
       "Attr3        0.095490\n",
       "Attr4        9.980499\n",
       "Attr5    -1347.662372\n",
       "             ...     \n",
       "Attr61      13.935361\n",
       "Attr62     135.536989\n",
       "Attr63       9.095149\n",
       "Attr64      35.766800\n",
       "class        0.047129\n",
       "Length: 65, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting from object to float64\n",
    "\n",
    "bankruptcy_df['Attr1'] = pd.to_numeric(bankruptcy_df['Attr1'])\n",
    "bankruptcy_df['Attr2'] = pd.to_numeric(bankruptcy_df['Attr2'])\n",
    "bankruptcy_df['Attr3'] = pd.to_numeric(bankruptcy_df['Attr3'])\n",
    "bankruptcy_df['Attr4'] = pd.to_numeric(bankruptcy_df['Attr4'])\n",
    "bankruptcy_df['Attr5'] = pd.to_numeric(bankruptcy_df['Attr5'])\n",
    "bankruptcy_df['Attr6'] = pd.to_numeric(bankruptcy_df['Attr6'])\n",
    "bankruptcy_df['Attr7'] = pd.to_numeric(bankruptcy_df['Attr7'])\n",
    "bankruptcy_df['Attr8'] = pd.to_numeric(bankruptcy_df['Attr8'])\n",
    "bankruptcy_df['Attr9'] = pd.to_numeric(bankruptcy_df['Attr9'])\n",
    "bankruptcy_df['Attr10'] = pd.to_numeric(bankruptcy_df['Attr10'])\n",
    "bankruptcy_df['Attr11'] = pd.to_numeric(bankruptcy_df['Attr11'])\n",
    "bankruptcy_df['Attr12'] = pd.to_numeric(bankruptcy_df['Attr12'])\n",
    "bankruptcy_df['Attr13'] = pd.to_numeric(bankruptcy_df['Attr13'])\n",
    "bankruptcy_df['Attr14'] = pd.to_numeric(bankruptcy_df['Attr14'])\n",
    "bankruptcy_df['Attr15'] = pd.to_numeric(bankruptcy_df['Attr15'])\n",
    "bankruptcy_df['Attr16'] = pd.to_numeric(bankruptcy_df['Attr16'])\n",
    "bankruptcy_df['Attr17'] = pd.to_numeric(bankruptcy_df['Attr17'])\n",
    "bankruptcy_df['Attr18'] = pd.to_numeric(bankruptcy_df['Attr18'])\n",
    "bankruptcy_df['Attr19'] = pd.to_numeric(bankruptcy_df['Attr19'])\n",
    "bankruptcy_df['Attr20'] = pd.to_numeric(bankruptcy_df['Attr20'])\n",
    "bankruptcy_df['Attr21'] = pd.to_numeric(bankruptcy_df['Attr21'])\n",
    "bankruptcy_df['Attr22'] = pd.to_numeric(bankruptcy_df['Attr22'])\n",
    "bankruptcy_df['Attr23'] = pd.to_numeric(bankruptcy_df['Attr23'])\n",
    "bankruptcy_df['Attr24'] = pd.to_numeric(bankruptcy_df['Attr24'])\n",
    "bankruptcy_df['Attr25'] = pd.to_numeric(bankruptcy_df['Attr25'])\n",
    "bankruptcy_df['Attr26'] = pd.to_numeric(bankruptcy_df['Attr26'])\n",
    "bankruptcy_df['Attr27'] = pd.to_numeric(bankruptcy_df['Attr27'])\n",
    "bankruptcy_df['Attr28'] = pd.to_numeric(bankruptcy_df['Attr28'])\n",
    "bankruptcy_df['Attr29'] = pd.to_numeric(bankruptcy_df['Attr29'])\n",
    "bankruptcy_df['Attr30'] = pd.to_numeric(bankruptcy_df['Attr30'])\n",
    "bankruptcy_df['Attr31'] = pd.to_numeric(bankruptcy_df['Attr31'])\n",
    "bankruptcy_df['Attr32'] = pd.to_numeric(bankruptcy_df['Attr32'])\n",
    "bankruptcy_df['Attr33'] = pd.to_numeric(bankruptcy_df['Attr33'])\n",
    "bankruptcy_df['Attr34'] = pd.to_numeric(bankruptcy_df['Attr34'])\n",
    "bankruptcy_df['Attr35'] = pd.to_numeric(bankruptcy_df['Attr35'])\n",
    "bankruptcy_df['Attr36'] = pd.to_numeric(bankruptcy_df['Attr36'])\n",
    "bankruptcy_df['Attr37'] = pd.to_numeric(bankruptcy_df['Attr37'])\n",
    "bankruptcy_df['Attr38'] = pd.to_numeric(bankruptcy_df['Attr38'])\n",
    "bankruptcy_df['Attr39'] = pd.to_numeric(bankruptcy_df['Attr39'])\n",
    "bankruptcy_df['Attr40'] = pd.to_numeric(bankruptcy_df['Attr40'])\n",
    "bankruptcy_df['Attr41'] = pd.to_numeric(bankruptcy_df['Attr41'])\n",
    "bankruptcy_df['Attr42'] = pd.to_numeric(bankruptcy_df['Attr42'])\n",
    "bankruptcy_df['Attr43'] = pd.to_numeric(bankruptcy_df['Attr43'])\n",
    "bankruptcy_df['Attr44'] = pd.to_numeric(bankruptcy_df['Attr44'])\n",
    "bankruptcy_df['Attr45'] = pd.to_numeric(bankruptcy_df['Attr45'])\n",
    "bankruptcy_df['Attr46'] = pd.to_numeric(bankruptcy_df['Attr46'])\n",
    "bankruptcy_df['Attr47'] = pd.to_numeric(bankruptcy_df['Attr47'])\n",
    "bankruptcy_df['Attr48'] = pd.to_numeric(bankruptcy_df['Attr48'])\n",
    "bankruptcy_df['Attr49'] = pd.to_numeric(bankruptcy_df['Attr49'])\n",
    "bankruptcy_df['Attr50'] = pd.to_numeric(bankruptcy_df['Attr50'])\n",
    "bankruptcy_df['Attr51'] = pd.to_numeric(bankruptcy_df['Attr51'])\n",
    "bankruptcy_df['Attr52'] = pd.to_numeric(bankruptcy_df['Attr52'])\n",
    "bankruptcy_df['Attr53'] = pd.to_numeric(bankruptcy_df['Attr53'])\n",
    "bankruptcy_df['Attr54'] = pd.to_numeric(bankruptcy_df['Attr54'])\n",
    "bankruptcy_df['Attr55'] = pd.to_numeric(bankruptcy_df['Attr55'])\n",
    "bankruptcy_df['Attr56'] = pd.to_numeric(bankruptcy_df['Attr56'])\n",
    "bankruptcy_df['Attr57'] = pd.to_numeric(bankruptcy_df['Attr57'])\n",
    "bankruptcy_df['Attr58'] = pd.to_numeric(bankruptcy_df['Attr58'])\n",
    "bankruptcy_df['Attr59'] = pd.to_numeric(bankruptcy_df['Attr59'])\n",
    "bankruptcy_df['Attr60'] = pd.to_numeric(bankruptcy_df['Attr60'])\n",
    "bankruptcy_df['Attr61'] = pd.to_numeric(bankruptcy_df['Attr61'])\n",
    "bankruptcy_df['Attr62'] = pd.to_numeric(bankruptcy_df['Attr62'])\n",
    "bankruptcy_df['Attr63'] = pd.to_numeric(bankruptcy_df['Attr63'])\n",
    "bankruptcy_df['Attr64'] = pd.to_numeric(bankruptcy_df['Attr64'])\n",
    "\n",
    "bankruptcy_df.dtypes\n",
    "\n",
    "bankruptcy_df.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check profile report of the dataset\n",
    "\n",
    "profile = bankruptcy_df.profile_report(title='Pandas Profiling Report')\n",
    "profile.to_file(output_file=\"outputfileno3.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping duplicate values \n",
    "\n",
    "bankruptcy_df.drop_duplicates(keep=False,inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete because of large number of missing values > 45%\n",
    "\n",
    "del bankruptcy_df['Attr37']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attr1     0\n",
       "Attr2     0\n",
       "Attr3     0\n",
       "Attr4     0\n",
       "Attr5     0\n",
       "         ..\n",
       "Attr61    0\n",
       "Attr62    0\n",
       "Attr63    0\n",
       "Attr64    0\n",
       "class     0\n",
       "Length: 64, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imputing missing values by mean\n",
    "\n",
    "bankruptcy_df.fillna(bankruptcy_df.mean(), inplace=True)\n",
    "\n",
    "#number of missing values\n",
    "\n",
    "bankruptcy_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation analysis\n",
    "\n",
    "corrmat = bankruptcy_df.corr() \n",
    "  \n",
    "corrmat.to_csv(\"correlation-analysis.csv\")    \n",
    "    \n",
    "#plotting correlation graph   \n",
    "\n",
    "import seaborn as sns \n",
    "\n",
    "f, ax = plt.subplots(figsize =(15, 15))\n",
    "sns.heatmap(corrmat, ax = ax, cmap =\"YlGnBu\", linewidths = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete because of high correlation\n",
    "\n",
    "bankruptcy_df = bankruptcy_df.drop(['Attr11','Attr14','Attr16','Attr22','Attr23','Attr25','Attr3','Attr26','Attr31','Attr35',\n",
    "        'Attr38','Attr42','Attr44','Attr47','Attr46','Attr48','Attr49','Attr50','Attr51','Attr52','Attr53','Attr54',\n",
    "        'Attr6', 'Attr62', 'Attr7','Attr8'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10329, 38)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bankruptcy_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # FEATURE SELECTION USING RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of feature names\n",
    "feature_labels = ['Attr1','Attr2','Attr4','Attr5','Attr9','Attr10',\n",
    "              'Attr12','Attr13','Attr15','Attr17','Attr18','Attr19','Attr20',\n",
    "              'Attr21','Attr24','Attr27','Attr28','Attr29','Attr30',\n",
    "              'Attr32','Attr33','Attr34','Attr36','Attr39','Attr40',\n",
    "              'Attr41','Attr43','Attr45','Attr55','Attr56','Attr57','Attr58','Attr59','Attr60',\n",
    "              'Attr61','Attr63','Attr64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Attr1', 0.01983228212653285)\n",
      "('Attr2', 0.020190044866957697)\n",
      "('Attr4', 0.02048424235033621)\n",
      "('Attr5', 0.019749191934878417)\n",
      "('Attr9', 0.032749329457449475)\n",
      "('Attr10', 0.02160633735501335)\n",
      "('Attr12', 0.021669119283337184)\n",
      "('Attr13', 0.027162600902615575)\n",
      "('Attr15', 0.026719733829463847)\n",
      "('Attr17', 0.019919186945063234)\n",
      "('Attr18', 0.01992583241718601)\n",
      "('Attr19', 0.021092393033717863)\n",
      "('Attr20', 0.018740499140047637)\n",
      "('Attr21', 0.04346627143997887)\n",
      "('Attr24', 0.036196339956857795)\n",
      "('Attr27', 0.08619408936770316)\n",
      "('Attr28', 0.02214337450501972)\n",
      "('Attr29', 0.03718953256336151)\n",
      "('Attr30', 0.019269530359296128)\n",
      "('Attr32', 0.019446532747336643)\n",
      "('Attr33', 0.021264819070845944)\n",
      "('Attr34', 0.06000760261739276)\n",
      "('Attr36', 0.023679943886897346)\n",
      "('Attr39', 0.027590991482345742)\n",
      "('Attr40', 0.027180340598837192)\n",
      "('Attr41', 0.026957230250561057)\n",
      "('Attr43', 0.018971216693684775)\n",
      "('Attr45', 0.018953033010069564)\n",
      "('Attr55', 0.028440190149681688)\n",
      "('Attr56', 0.036165305982888675)\n",
      "('Attr57', 0.021027442051238146)\n",
      "('Attr58', 0.04042028607106147)\n",
      "('Attr59', 0.015411424935862098)\n",
      "('Attr60', 0.01945895408632963)\n",
      "('Attr61', 0.022295288128343693)\n",
      "('Attr63', 0.017806876043400324)\n",
      "('Attr64', 0.020622590358406714)\n"
     ]
    }
   ],
   "source": [
    "#Create X from the features\n",
    "X = bankruptcy_df[feature_labels].values\n",
    "\n",
    "# Create y from output\n",
    "y = bankruptcy_df['class'].values.ravel()\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "\n",
    "# Train the classifier\n",
    "rf_clf.fit(X, y)\n",
    "\n",
    "# Print the name and gini importance of each feature\n",
    "for feature in zip(feature_labels, rf_clf.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                 class_weight=None,\n",
       "                                                 criterion='gini',\n",
       "                                                 max_depth=None,\n",
       "                                                 max_features='auto',\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=1,\n",
       "                                                 min_samples_split=2,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 n_estimators=10000, n_jobs=-1,\n",
       "                                                 oob_score=False,\n",
       "                                                 random_state=0, verbose=0,\n",
       "                                                 warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=0.03)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a selector object that will use the random forest classifier to identify\n",
    "# features that have an importance of more than 0.03\n",
    "sfm = SelectFromModel(rf_clf, threshold=0.03)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attr9\n",
      "Attr21\n",
      "Attr24\n",
      "Attr27\n",
      "Attr29\n",
      "Attr34\n",
      "Attr56\n",
      "Attr58\n"
     ]
    }
   ],
   "source": [
    "#Print the names of the most important features\n",
    "\n",
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    print(feature_labels[feature_list_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imp_features = sfm.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10329,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting X_filtered to Dataframe\n",
    "\n",
    "X_imp_features = pd.DataFrame(data=X_imp_features,\n",
    "          index=np.arange(1, 10330),\n",
    "          columns=np.arange(1, 9))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # SMOTE+ENN & DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives:  1792\n",
      "False Positives:  176\n",
      "False Negatives:  73\n",
      "True Positives:  26\n",
      "True Negatives:  1719\n",
      "False Positives:  249\n",
      "False Negatives:  40\n",
      "True Positives:  58\n",
      "True Negatives:  1724\n",
      "False Positives:  244\n",
      "False Negatives:  43\n",
      "True Positives:  55\n",
      "True Negatives:  1772\n",
      "False Positives:  195\n",
      "False Negatives:  47\n",
      "True Positives:  51\n",
      "True Negatives:  1771\n",
      "False Positives:  196\n",
      "False Negatives:  44\n",
      "True Positives:  54\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-22-e8ad2fb9e34c>, line 34)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-22-e8ad2fb9e34c>\"\u001b[1;36m, line \u001b[1;32m34\u001b[0m\n\u001b[1;33m    return np.array(tn_dt)\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn_dt = []\n",
    "fp_dt = []\n",
    "fn_dt = []\n",
    "tp_dt = []\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "for train_idx_dt, test_idx_dt, in cv.split(X_imp_features, y):\n",
    "    X_train_dt, y_train_dt = X[train_idx_dt], y[train_idx_dt]\n",
    "    X_test_dt, y_test_dt = X[test_idx_dt], y[test_idx_dt]\n",
    "    X_train_dt, y_train_dt = SMOTEENN().fit_resample(X_train_dt, y_train_dt)\n",
    "    \n",
    "    dt = DecisionTreeClassifier()\n",
    "    dt.fit(X_train_dt, y_train_dt)\n",
    "    y_dt_pred = dt.predict(X_test_dt)\n",
    "    accuracy_score(y_test_dt, y_dt_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_dt, y_dt_pred).ravel()\n",
    "    tn_dt.append(tn)\n",
    "    fp_dt.append(fp)\n",
    "    fn_dt.append(fn)\n",
    "    tp_dt.append(tp)\n",
    "    print(\"True Negatives: \",tn)\n",
    "    print(\"False Positives: \",fp)\n",
    "    print(\"False Negatives: \",fn)\n",
    "    print(\"True Positives: \",tp)\n",
    "return np.array(tn_dt)\n",
    "return np.array(fp_dt)\n",
    "return np.array(fn_dt)\n",
    "return np.array(tp_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Avg_tn_dt = round(sum(tn_dt)/len(tn_dt))\n",
    "Avg_fp_dt = round(sum(fp_dt)/len(fp_dt))\n",
    "Avg_fn_dt = round(sum(fn_dt)/len(fn_dt))\n",
    "Avg_tp_dt = round(sum(tp_dt)/len(tp_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity 0.89\n",
      "Recall / Sensitivity 0.50\n",
      "Geometric Mean Score 0.67\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "#Specificity\n",
    "Specificity_dt = Avg_tn_dt/(Avg_tn_dt+Avg_fp_dt) \n",
    "print(\"Specificity {:0.2f}\".format(Specificity_dt))\n",
    "\n",
    "#Recall \n",
    "Recall_dt = Avg_tp_dt/(Avg_tp_dt+Avg_fn_dt) \n",
    "print(\"Recall / Sensitivity {:0.2f}\".format(Recall_dt))\n",
    "\n",
    "#Precision\n",
    "Precision_dt = Avg_tp_dt/(Avg_tp_dt + Avg_fp_dt)\n",
    "\n",
    "#GMean\n",
    "GM_dt = math.sqrt(Specificity_dt*Recall_dt)\n",
    "print(\"Geometric Mean Score {:0.2f}\".format(GM_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # SMOTE+ENN & KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives:  1464\n",
      "False Positives:  504\n",
      "False Negatives:  71\n",
      "True Positives:  28\n",
      "True Negatives:  1424\n",
      "False Positives:  544\n",
      "False Negatives:  38\n",
      "True Positives:  60\n",
      "True Negatives:  1403\n",
      "False Positives:  565\n",
      "False Negatives:  41\n",
      "True Positives:  57\n",
      "True Negatives:  1514\n",
      "False Positives:  453\n",
      "False Negatives:  48\n",
      "True Positives:  50\n",
      "True Negatives:  1418\n",
      "False Positives:  549\n",
      "False Negatives:  36\n",
      "True Positives:  62\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-25-c183199a9972>, line 39)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-25-c183199a9972>\"\u001b[1;36m, line \u001b[1;32m39\u001b[0m\n\u001b[1;33m    return np.array(tn_knn)\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import neighbors\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn_knn = []\n",
    "fp_knn = []\n",
    "fn_knn = []\n",
    "tp_knn = []\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "for train_idx_knn, test_idx_knn, in cv.split(X_imp_features, y):\n",
    "    X_train_knn, y_train_knn = X[train_idx_knn], y[train_idx_knn]\n",
    "    X_test_knn, y_test_knn = X[test_idx_knn], y[test_idx_knn]\n",
    "    X_train_knn, y_train_knn = SMOTEENN().fit_resample(X_train_knn, y_train_knn)\n",
    "    \n",
    "    clf_knn = neighbors.KNeighborsClassifier()\n",
    "    clf_knn.fit(X_train_knn, y_train_knn)\n",
    "    \n",
    "    y_knn_pred = clf_knn.predict(X_test_knn)\n",
    "    accuracy_score(y_test_knn, y_knn_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_knn, y_knn_pred).ravel()\n",
    "    tn_knn.append(tn)\n",
    "    fp_knn.append(fp)\n",
    "    fn_knn.append(fn)\n",
    "    tp_knn.append(tp)\n",
    "    print(\"True Negatives: \",tn)\n",
    "    print(\"False Positives: \",fp)\n",
    "    print(\"False Negatives: \",fn)\n",
    "    print(\"True Positives: \",tp)\n",
    "return np.array(tn_knn)\n",
    "return np.array(fp_knn)\n",
    "return np.array(fn_knn)\n",
    "return np.array(tp_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Avg_tn_knn = round(sum(tn_knn)/len(tn_knn))\n",
    "Avg_fp_knn = round(sum(fp_knn)/len(fp_knn))\n",
    "Avg_fn_knn = round(sum(fn_knn)/len(fn_knn))\n",
    "Avg_tp_knn = round(sum(tp_knn)/len(tp_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity 0.73\n",
      "Recall / Sensitivity 0.52\n",
      "Geometric Mean Score 0.62\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "#Specificity\n",
    "Specificity_knn = Avg_tn_knn/(Avg_tn_knn+Avg_fp_knn) \n",
    "print(\"Specificity {:0.2f}\".format(Specificity_knn))\n",
    "\n",
    "#Recall \n",
    "Recall_knn = Avg_tp_knn/(Avg_tp_knn+Avg_fn_knn) \n",
    "print(\"Recall / Sensitivity {:0.2f}\".format(Recall_knn))\n",
    "\n",
    "#Precision\n",
    "Precision_knn = Avg_tp_knn/(Avg_tp_knn + Avg_fp_knn)\n",
    "\n",
    "#GMean\n",
    "GM_knn = math.sqrt(Specificity_knn*Recall_knn)\n",
    "print(\"Geometric Mean Score {:0.2f}\".format(GM_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # SMOTE+ENN & ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives:  1766\n",
      "False Positives:  202\n",
      "False Negatives:  73\n",
      "True Positives:  26\n",
      "True Negatives:  1650\n",
      "False Positives:  318\n",
      "False Negatives:  33\n",
      "True Positives:  65\n",
      "True Negatives:  1683\n",
      "False Positives:  285\n",
      "False Negatives:  33\n",
      "True Positives:  65\n",
      "True Negatives:  1736\n",
      "False Positives:  231\n",
      "False Negatives:  37\n",
      "True Positives:  61\n",
      "True Negatives:  1748\n",
      "False Positives:  219\n",
      "False Negatives:  42\n",
      "True Positives:  56\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-29-d57de1b0ce85>, line 53)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-29-d57de1b0ce85>\"\u001b[1;36m, line \u001b[1;32m53\u001b[0m\n\u001b[1;33m    return np.array(tn_ada)\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import neighbors\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn_ada = []\n",
    "fp_ada = []\n",
    "fn_ada = []\n",
    "tp_ada = []\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "for train_idx_ada, test_idx_ada, in cv.split(X_imp_features, y):\n",
    "    X_train_ada, y_train_ada = X[train_idx_ada], y[train_idx_ada]\n",
    "    X_test_ada, y_test_ada = X[test_idx_ada], y[test_idx_ada]\n",
    "    X_train_ada, y_train_ada = SMOTEENN().fit_resample(X_train_ada, y_train_ada)\n",
    "    \n",
    "    ada_classifier = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=200)\n",
    "    ada_classifier.fit(X_train_ada, y_train_ada)\n",
    "    \n",
    "    #clf_knn = neighbors.KNeighborsClassifier()\n",
    "    #clf_knn.fit(X_train_knn, y_train_knn)\n",
    "    \n",
    "    y_ada_pred = ada_classifier.predict(X_test_ada)\n",
    "    accuracy_score(y_test_ada, y_ada_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_ada, y_ada_pred).ravel()\n",
    "    tn_ada.append(tn)\n",
    "    fp_ada.append(fp)\n",
    "    fn_ada.append(fn)\n",
    "    tp_ada.append(tp)\n",
    "    print(\"True Negatives: \",tn)\n",
    "    print(\"False Positives: \",fp)\n",
    "    print(\"False Negatives: \",fn)\n",
    "    print(\"True Positives: \",tp)\n",
    "return np.array(tn_ada)\n",
    "return np.array(fp_ada)\n",
    "return np.array(fn_ada)\n",
    "return np.array(tp_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Avg_tn_ada = round(sum(tn_ada)/len(tn_ada))\n",
    "Avg_fp_ada = round(sum(fp_ada)/len(fp_ada))\n",
    "Avg_fn_ada = round(sum(fn_ada)/len(fn_ada))\n",
    "Avg_tp_ada = round(sum(tp_ada)/len(tp_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity 0.87\n",
      "Recall / Sensitivity 0.56\n",
      "Geometric Mean Score 0.70\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "#Specificity\n",
    "Specificity_ada = Avg_tn_ada/(Avg_tn_ada+Avg_fp_ada) \n",
    "print(\"Specificity {:0.2f}\".format(Specificity_ada))\n",
    "\n",
    "#Recall \n",
    "Recall_ada = Avg_tp_ada/(Avg_tp_ada+Avg_fn_ada) \n",
    "print(\"Recall / Sensitivity {:0.2f}\".format(Recall_ada))\n",
    "\n",
    "#Precision\n",
    "Precision_ada = Avg_tp_ada/(Avg_tp_ada + Avg_fp_ada)\n",
    "\n",
    "#GMean\n",
    "GM_ada = math.sqrt(Specificity_ada*Recall_ada)\n",
    "print(\"Geometric Mean Score {:0.2f}\".format(GM_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
